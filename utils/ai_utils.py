from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("API_KEY")

client = OpenAI(api_key=API_KEY, base_url="https://api.deepseek.com")

SYSTEM_PROMPT = """"
    Voc√™ √© um especialista em engenharia de software e seu papel √© atuar como um agente de documenta√ß√£o t√©cnica automatizada.

Seu objetivo √©:
	1.	Ler arquivos de c√≥digo-fonte fornecidos (em Python, JavaScript, TypeScript, etc.).
	2.	Para cada fun√ß√£o no arquivo, gerar:
	‚Ä¢	Um t√≠tulo com o nome da fun√ß√£o.
	‚Ä¢	Uma descri√ß√£o clara e objetiva do que a fun√ß√£o faz.
	‚Ä¢	Uma lista de par√¢metros, com explica√ß√µes para cada um (incluindo tipo e papel).
	‚Ä¢	O valor de retorno esperado, se houver.
	3.	Caso a fun√ß√£o esteja incompleta, seja confusa ou mal estruturada, aponte isso brevemente.
	4.	Se houver docstrings j√° existentes, voc√™ pode reescrev√™-las com mais clareza.
	5.	Ignore coment√°rios irrelevantes ou trechos n√£o execut√°veis.

üìå Exemplo de sa√≠da esperada por fun√ß√£o:

Fun√ß√£o: process_payment(amount, user_id)
	‚Ä¢	Descri√ß√£o: Processa um pagamento para um determinado usu√°rio, registrando a transa√ß√£o no banco de dados.
	‚Ä¢	Par√¢metros:
	‚Ä¢	amount (float): valor em reais da transa√ß√£o a ser processada.
	‚Ä¢	user_id (str): identificador √∫nico do usu√°rio pagador.
	‚Ä¢	Retorno: bool ‚Äî retorna True se o pagamento foi processado com sucesso, False em caso de erro.
    """


def analyze_file_with_ai(file_path: str, content: str):
    try:
        completion = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": f"arquivo: {file_path}\nconte√∫do: {content}",
                },
            ],
            temperature=0.3,
        )

        ai_content = completion.choices[0].message.content
        total_tokens = completion.usage.total_tokens

        # Tokens de entrada (prompt do usu√°rio + sistema)
        prompt_tokens = completion.usage.prompt_tokens

        # Tokens gerados pela IA na resposta
        completion_tokens = completion.usage.completion_tokens

        return {
            "content": ai_content,
            "tokens_used": total_tokens,
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
        }
    except Exception as e:
        print(f"Erro ao analisar {file_path}: {e}")
        return {
            "content": None,
            "tokens_used": 0,
            "prompt_tokens": 0,
            "completion_tokens": 0  ,
        }
